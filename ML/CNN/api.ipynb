{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dipy.reconst.dki as dki\n",
    "import dipy.reconst.dti as dti\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.data import get_fnames\n",
    "from dipy.io.gradients import read_bvals_bvecs\n",
    "from dipy.io.image import load_nifti\n",
    "from dipy.segment.mask import median_otsu\n",
    "from scipy.misc import face\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import nibabel as nib\n",
    "from scipy.ndimage import zoom\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageOps\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing model and initializing visualization model\n",
    "model = tf.keras.models.load_model(\"cnnBrainDepressionBest\")\n",
    "successive_outputs = [layer.output for layer in model.layers]\n",
    "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
    "\n",
    "def dti_process(nii_file,bval_file,bvec_file):\n",
    "    data, affine = load_nifti(nii_file)\n",
    "    bvals, bvecs = read_bvals_bvecs(bval_file, bvec_file)\n",
    "    gtab = gradient_table(bvals, bvecs)\n",
    "\n",
    "    # First of all, we mask and crop the data. This is a quick way to avoid calculating Tensors on the background of the image. This is done using DIPYâ€™s mask module.\n",
    "    maskdata, mask = median_otsu(data, vol_idx=range(10, 50), median_radius=3, numpass=1, autocrop=True, dilate=2)\n",
    "\n",
    "    # Now that we have prepared the datasets we can go forward with the voxel reconstruction. First, we instantiate the Tensor model in the following way.\n",
    "    tenmodel = dti.TensorModel(gtab)\n",
    "    # print(gtab)\n",
    "\n",
    "    # Fitting the data is very simple. We just need to call the fit method of the TensorModel in the following way:\n",
    "    tenfit = tenmodel.fit(maskdata, mask=mask)\n",
    "\n",
    "    # qf is the tensor that contains the diffusion matrix for each voxel in the 3D space\n",
    "    qf = tenfit.quadratic_form\n",
    "    # print(qf.shape)\n",
    "\n",
    "    # Eigen Values and Vectors\n",
    "    eigvals, eigvecs = dti.decompose_tensor(qf)\n",
    "\n",
    "    # Diffusion metrics\n",
    "    fa = tenfit.fa\n",
    "    md = tenfit.md\n",
    "    rd = tenfit.rd\n",
    "    ad = tenfit.ad\n",
    "    # print(fa.shape,md.shape,rd.shape,ad.shape)\n",
    "    fa_img = nib.Nifti1Image(fa.astype(np.float32), affine)\n",
    "    nib.save(fa_img, 'tensor_fa.nii.gz')\n",
    "    return fa,md,rd,ad\n",
    "\n",
    "def processNiiFile(niiFile, bvecFile, bvalFile):\n",
    "    fa, md, rd, ad = [zoom(x, (50/x.shape[0], 50/x.shape[1], 50/x.shape[2])) for x in dti_process(niiFile, bvecFile, bvalFile)]\n",
    "\n",
    "    inputMat = np.moveaxis(np.array([fa]), 0, -1)\n",
    "\n",
    "    successive_feature_maps = visualization_model.predict(np.array([inputMat]))\n",
    "\n",
    "    for i in [0, 2, 4, 7]:\n",
    "        for patient in successive_feature_maps[i]:\n",
    "            newImages = np.moveaxis(patient, -1, 0)\n",
    "            data, affine = load_nifti(niiFile)\n",
    "            for x in range(4):\n",
    "                if x == 3:\n",
    "                    fa_img = nib.Nifti1Image(newImages[x].astype(np.float32), affine)\n",
    "                    nib.save(fa_img, f'tensor_fa50_{i}_{x}.nii.gz')\n",
    "                    twoDimage = nib.load(f\"tensor_fa50_{i}_{x}.nii.gz\").get_fdata()\n",
    "                    # twoDimage = np.array(fa_img.slicer[0:1])\n",
    "                    twoDimage = zoom(twoDimage[:, 30, :], (20, 20))\n",
    "                    # twoDimage = np.moveaxis(twoDimage, -1, 0)\n",
    "                    print(twoDimage.shape)\n",
    "                    \n",
    "                    rescaled = (255.0 / twoDimage.max() * (twoDimage - twoDimage.min())).astype(np.uint8)\n",
    "\n",
    "                    im = Image.fromarray(rescaled)\n",
    "                    im.save(f\"tensor_fa50_{i}_{x}.png\")\n",
    "                    \n",
    "                    # plt.imshow(twoDimage[0])\n",
    "                    # plt.show()\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1000)\n",
      "(1000, 1000)\n",
      "(1000, 1000)\n",
      "(1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "processNiiFile(\"D:\\\\Smart India Hackathon 2022\\\\ML\\\\CNN\\\\park4\\\\p06933\\\\p06933_bmatrix_1000.nii.gz\", \"D:\\\\Smart India Hackathon 2022\\\\ML\\\\CNN\\\\park4\\\\p06933\\\\p06933_bval_1000\", \"D:\\\\Smart India Hackathon 2022\\\\ML\\\\CNN\\\\park4\\\\p06933\\\\p06933_grad_1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b606b6647b27b9b82273d4273c5cec9713937445ade99beb07b64c9b28adcf3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
